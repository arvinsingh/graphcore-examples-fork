{
    "bert_model_name": "bert-large-uncased",
    "global_batch": {
        "replicas": 4,
        "micro_batch_size": 2,
        "grad_acc_steps_per_replica": 40
    },
    "num_epochs": 3,
    "ipu_config": {
        "pipeline_stages": [
            ["emb", "hid", "hid", "hid"],
            ["hid", "hid", "hid", "hid", "hid", "hid", "hid"],
            ["hid", "hid", "hid", "hid", "hid", "hid", "hid"],
            ["hid", "hid", "hid", "hid", "hid", "hid", "hid", "enc_out", "pool"],
            ["qa_head"]
        ],
        "pipeline_device_mapping": [0, 1, 2, 3, 0],
        "matmul_available_memory_proportion_per_pipeline_stage": [0.1, 0.15, 0.15, 0.15],
        "replicated_tensor_sharding": false
    },
    "optimizer_opts": {
        "name": "LAMB",
        "weight_decay_rate": 0.01,
        "learning_rate": {
            "schedule_name": "up_down",
            "max_learning_rate": 1e-3,
            "warmup_frac": 0.3
        }
    },
    "seed": 1984,
    "global_batches_per_log": 1,
    "enable_wandb": false,
    "wandb_tags": ["squad_fine_tuning"],
    "dataset_dir": "./cache/",
    "output_dir": "./output_dir_hf/"
}
